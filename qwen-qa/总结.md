# 总结

### 1 难点

* pdf及pdf中的表格处理；
* 文本切分细度；
* 数据库清洗、处理；
* 相近问题意图识别（尤其是文档检索和db检索）；
* 问题处理，意图补全；
* 处理多表之间的复杂关联，如理解基金股票持仓明细与A股日行情表的连接，并确保查询的高准确性；
* 处理长文本的复杂结构，确保信息完整性。对超长文本，需合理分块，并从文档分块中准确提炼答案；
* 对于模型不稳定输出格式的处理；

### 2 总体思路

##### 2-1 数据处理

**PDF：**

因为使用灵积api调用qwen大模型，因此采用较小的文本块（长度500，overlap 10%），采用向量数据库存储。使用章节标题等建立文档树。

对于每个文本块，要清洗其中可能存在的乱码字符、无用符号（\/\等），多余换行符等可能影响语义的符号。

对于每个pdf的内容，选择TF-IDF算法或BM25算法抽取pdf关键词以及公司名称等重要信息（从文件名或封面页提取），并维护关键词库。考虑到关键词抽取效果以及存储查询开销，只针对每个pdf文档而并非针对切分后的文本块进行关键词对应。也可以使用大模型进行关键词抽取，但需要考虑数据隐私以及处理效率的问题。

对于pdf中的表格，抽取后单独存储。由于多余制表符会影响向量相似度计算，因此使用提示和简单方式来表示表格（下面是一个表格：\n表头：xxxx\n ;\n），复杂表格先由工具提取，然后再处理，包括null值填充等。

**数据库：**

对于数据库表，抽取其主要信息。包括：表名，每个表中的字段名称以及数据类型，所有主键和外键；该信息将会作为prompt的一部分。

对一些字段内容进行处理，例如时间信息，20220101(TEXT)格式无法被数据库时间处理函数(例如STRFTIME)识别，因此需要对其进行转换，2022-01-01(TEXT)。

##### 2-2 问题处理

意图识别：由于问题相似度较高，所以需要意图识别工具来对问题进行分类，使用LLM对问题进行分类以及需要使用的相关工具，决定解决问题的步骤。可以使用LLM或者经过fine-tuning的小模型。

意图补全：对于用户问题，可能要使用专业词汇来替换用户问题中的口语化表述；中文数字替换阿拉伯数字等

子任务识别：对于多个问题并列的情况，需要进行子任务分解，讲问题分解为多步骤、多任务，依次进行回答

##### 2-2 知识库问答

问题关键词提取：由于问题一般较短，使用TF-IDF等词频算法并不合适，因此采用填充模版（公司名称，时间等等）+LLM的方法，提取需要的关键词；

关键词检索：A.对公司名称等关键词首先通过向量相似度检索，检索相关文档，这一步根据问题类型，如果针对单个公司，则top1，如果是统计类问题，则取大于阈值的所有检索结果；B.使用问题需求的关键词查询文档树，多路回召得到结果。

知识问答：将多路召回的文本块去掉头尾不完整句子（避免出现幻觉），分别填充prompt得到一些答案，最后答案汇总再次填充prompt得到最终答案。

##### 2-3 数据库查询

Text to SQL：提高prompt的信噪比，去掉信息熵较低的词语，如stopword(的地得、请）、“保留小数”。容易查询错误的关键词，如公司名词，可以在prompt中着重强调。问题存在计算的话，不应包含在SQL语句生成里，要分解子任务。

SQL纠错：为了提高稳定性，可以对生成的SQL语句再次送入LLM勘误，但是容易没错硬改，因此还是采用p-tuning或in context learning等方法提高生成准确性比较好。纠错可以放在SQL语句执行出错时处理错误。

SQL模版：对于简单查询问题，可以使用SQL模版来提高LLM输出的稳定性。

查询结果：将查询结果与问题组成自然语言进行返回，有助于后续处理。

##### 2-4 关键词提取

规则匹配+LLM。对年份、主体、客体等着重提取。

对并列主体或客体的情况，需要将其拆分、展开并扁平化。

对于一些隐含计算的术语，例如，增长率，比值等，应该维护相应的自然语言形式的计算公式。
