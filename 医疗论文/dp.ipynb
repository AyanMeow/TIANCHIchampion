{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jieba\n",
    "import transformers as ts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ark_nlp.model.ner.global_pointer_bert import Dataset,Tokenizer,GlobalPointerBertConfig,GlobalPointerBert,get_default_model_optimizer,Task,Predictor\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ner_list</th>\n",
       "      <th>type</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>血管内皮生长因子表达水平与宫颈癌患者预后的关系</td>\n",
       "      <td>[{'mention': '血管内皮生长因子表达水平与宫颈癌患者预后的关系', 'label...</td>\n",
       "      <td>Title</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>目的探讨地尔硫卓在治疗扩张型心肌病中的临床疗效。方法将2014年9月至2017年12月在红河...</td>\n",
       "      <td>[{'mention': '探讨地尔硫卓在治疗扩张型心肌病中的临床疗效', 'label':...</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>2501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>地尔硫卓在治疗扩张型心肌病中的临床疗效观察</td>\n",
       "      <td>[{'mention': '地尔硫卓在治疗扩张型心肌病中的临床疗效观察', 'label':...</td>\n",
       "      <td>Title</td>\n",
       "      <td>2501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                            血管内皮生长因子表达水平与宫颈癌患者预后的关系   \n",
       "1  目的探讨地尔硫卓在治疗扩张型心肌病中的临床疗效。方法将2014年9月至2017年12月在红河...   \n",
       "2                              地尔硫卓在治疗扩张型心肌病中的临床疗效观察   \n",
       "\n",
       "                                            ner_list      type  doc_id  \n",
       "0  [{'mention': '血管内皮生长因子表达水平与宫颈癌患者预后的关系', 'label...     Title    2500  \n",
       "1  [{'mention': '探讨地尔硫卓在治疗扩张型心肌病中的临床疗效', 'label':...  Abstract    2501  \n",
       "2  [{'mention': '地尔硫卓在治疗扩张型心肌病中的临床疗效观察', 'label':...     Title    2501  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=pd.read_json('./datasets/train.json')\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data=[]\n",
    "context_data=[]\n",
    "lens=len(df_train)\n",
    "for i in range(0,lens):\n",
    "    if df_train.loc[i,'type'] == 'Title':\n",
    "        text=df_train.loc[i,'text'].replace(' ','')\n",
    "        label=[]\n",
    "        context_data.append({\n",
    "                'text':text,\n",
    "                'label':df_train.loc[i,'ner_list'][0]['label'],\n",
    "            })\n",
    "        for ner in df_train.loc[i,'ner_list']:\n",
    "            subtext=ner['mention'].replace(' ','')\n",
    "            sidx=text.find(subtext)\n",
    "            if sidx == -1:\n",
    "                continue\n",
    "            eidx=sidx+len(subtext)\n",
    "            label.append({\n",
    "                'start_idx':sidx,\n",
    "                'end_idx':eidx,\n",
    "                'type':ner['label'],\n",
    "                'entity':subtext,\n",
    "            })\n",
    "        title_data.append({\n",
    "            'text':text,\n",
    "            'label':label\n",
    "        })\n",
    "    else:\n",
    "        for ner in df_train.loc[i,'ner_list']:\n",
    "            context_data.append({\n",
    "                'text':ner['mention'],\n",
    "                'label':ner['label'],\n",
    "            })\n",
    "title_data=json.dumps(title_data,ensure_ascii = False)\n",
    "context_data=json.dumps(context_data,ensure_ascii = False)\n",
    "# with open('./datasets/title_train.json','w',encoding='utf-8')as f:\n",
    "#     f.write(title_data)\n",
    "#     f.close()\n",
    "with open('./datasets/context_title_train.json','w',encoding='utf-8')as f:\n",
    "    f.write(context_data)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list=['C-对比选项',\n",
    " 'C-研究方法',\n",
    " 'C-研究目的',\n",
    " 'I-其他干预',\n",
    " 'I-干预',\n",
    " 'I-教育/行为干预',\n",
    " 'I-药物干预',\n",
    " 'I-非药物干预',\n",
    " 'O-定性结论',\n",
    " 'O-定量结论',\n",
    " 'O-结论',\n",
    " 'O-结论主语',\n",
    " 'P-人群/患者类型',\n",
    " 'P-条件',\n",
    " 'P-研究对象',\n",
    " 'P-评估项',\n",
    " 'S-因素(病因/风险)分析',\n",
    " 'S-指南标准建议',\n",
    " 'S-治疗',\n",
    " 'S-病因学',\n",
    " 'S-统计分析',\n",
    " 'S-诊断',\n",
    " 'S-预后']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_data=pd.read_json('./datasets/title_train.json')\n",
    "title_data=title_data.iloc[0:100,:]\n",
    "title_data['text'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set,val_set=train_test_split(title_data,test_size=0.2,random_state=1234)\n",
    "train_set=train_set.reset_index(drop=True)\n",
    "val_set=val_set.reset_index(drop=True)\n",
    "train_set['label']=train_set['label'].apply(lambda x: str(x))\n",
    "val_set['label']=val_set['label'].apply(lambda x: str(x))\n",
    "len(train_set),len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds=Dataset(train_set,categories=label_list)\n",
    "valds=Dataset(val_set,categories=label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=ts.BertTokenizer.from_pretrained('../../model/macbert-base-chinese-medical-collation/')\n",
    "ttokenier=Tokenizer(vocab=tokenizer,max_seq_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds.convert_to_ids(ttokenier)\n",
    "valds.convert_to_ids(ttokenier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([ 101, 7770, 7574, 4510, 1143, 3780, 4545, 2714, 2595, 2151, 7568,\n",
       "        4142, 9653,  891,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0], dtype=int64),\n",
       " 'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n",
       " 'token_type_ids': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n",
       " 'label_ids': tensor(indices=tensor([[7],\n",
       "                        [1],\n",
       "                        [5]]),\n",
       "        values=tensor([1.]),\n",
       "        size=(23, 100, 100), nnz=1, layout=torch.sparse_coo)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainds.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ../../model/macbert-base-chinese-medical-collation/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from model import GlobalPointer,GlobalPointerCrossEntropy,GlobalPointerNERPredictor\n",
    "args={\n",
    "    'bert_dir':'../../model/macbert-base-chinese-medical-collation/'\n",
    "}\n",
    "bertModel=GlobalPointer(args,len(label_list),64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0   loss: 6.85793399810791\n",
      "epoch: 1   loss: 6.169060945510864\n",
      "epoch: 2   loss: 5.330308437347412\n",
      "epoch: 3   loss: 4.254041850566864\n",
      "epoch: 4   loss: 3.0130489468574524\n",
      "epoch: 5   loss: 1.8222541809082031\n",
      "epoch: 6   loss: 1.113606721162796\n",
      "epoch: 7   loss: 0.8432368859648705\n",
      "epoch: 8   loss: 0.6961652711033821\n",
      "epoch: 9   loss: 0.5927189439535141\n"
     ]
    }
   ],
   "source": [
    "train_dl=DataLoader(trainds.dataset,batch_size=16)\n",
    "loss_fn=GlobalPointerCrossEntropy()\n",
    "opt=torch.optim.Adam(bertModel.parameters(),lr=5e-5)\n",
    "for e in range(0,10):\n",
    "    train_loss=0\n",
    "    for step,bd in enumerate(train_dl):\n",
    "        ppp=bertModel(bd['input_ids'],bd['attention_mask'],bd['token_type_ids'])\n",
    "        loss=loss_fn(ppp,bd['label_ids'].to_dense())\n",
    "        train_loss+=loss.item()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    print('epoch:',e,'  loss:',train_loss/step)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text='常染色体显性多囊肾病的临床问题及其肾脏替代治疗的选择'\n",
    "mpred=GlobalPointerNERPredictor(bertModel,ttokenier,trainds.cat2id,tokenizer)\n",
    "result=mpred.predict_one_sample(test_text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class clf(nn.Module):\n",
    "    \"\"\"docstring for clf.\"\"\"\n",
    "    def __init__(self, bert_path,cat_num):\n",
    "        super(clf, self).__init__()\n",
    "        bcfg=ts.BertConfig.from_pretrained(bert_path)\n",
    "        self.bert=ts.BertModel.from_pretrained(bert_path,config=bcfg)\n",
    "        self.mlp=nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(768,512,),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512,cat_num),\n",
    "            nn.GELU(),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self,input_ids,attention_mask,token_type_ids):\n",
    "        last_hidden_state=self.bert(input_ids,attention_mask,token_type_ids)\n",
    "        logits=last_hidden_state[0][:,0,:]\n",
    "        logits=self.mlp(logits)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class medData(Dataset):\n",
    "    def __init__(self,texts,labels,tokenizer,maxlen,label_list) -> None:\n",
    "        super(medData,self).__init__()\n",
    "        self.text=[tokenizer(t,\n",
    "                            padding='max_length',\n",
    "                            max_length = maxlen) for t in texts]\n",
    "        self.labels=[label_list.index(l) for l in labels]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_ids=torch.LongTensor(self.text[index]['input_ids'])\n",
    "        attention_mask=torch.LongTensor(self.text[index]['attention_mask'])\n",
    "        token_type_ids=torch.LongTensor(self.text[index]['token_type_ids'])\n",
    "        label=torch.LongTensor([self.labels[index]])\n",
    "        return {'input_ids':input_ids,'attention_mask':attention_mask,'token_type_ids':token_type_ids},label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>血管内皮生长因子表达水平与宫颈癌患者预后的关系</td>\n",
       "      <td>S-诊断</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>探讨地尔硫卓在治疗扩张型心肌病中的临床疗效</td>\n",
       "      <td>C-研究目的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>将2014年9月至2017年12月在红河州第二人民医院内二科住院治疗的40例扩张型心肌病患者...</td>\n",
       "      <td>C-研究方法</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   label\n",
       "0                            血管内皮生长因子表达水平与宫颈癌患者预后的关系    S-诊断\n",
       "1                              探讨地尔硫卓在治疗扩张型心肌病中的临床疗效  C-研究目的\n",
       "2  将2014年9月至2017年12月在红河州第二人民医院内二科住院治疗的40例扩张型心肌病患者...  C-研究方法"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrain_df=pd.read_json('./datasets/context_title_train.json')\n",
    "ctrain_df=ctrain_df.iloc[0:200,:]\n",
    "ctrain_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrain_dataset=medData(ctrain_df['text'].__array__(),ctrain_df['label'].__array__(),tokenizer,128,label_list)\n",
    "ctrain_dl=DataLoader(ctrain_dataset,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 血 管 内 皮 生 长 因 子 表 达 水 平 与 宫 颈 癌 患 者 预 后 的 关 系 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ctrain_dataset.text[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ../../model/macbert-base-chinese-medical-collation/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "classfier=clf('../../model/macbert-base-chinese-medical-collation/',len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step,(bd,l) in enumerate(ctrain_dl):\n",
    "    logits=classfier(bd['input_ids'],bd['attention_mask'],bd['token_type_ids'])\n",
    "    pred=torch.max(logits,dim=-1)\n",
    "    #(b,n,c)——(b,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
