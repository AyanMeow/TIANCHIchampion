{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jieba\n",
    "import transformers as ts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ark_nlp.model.ner.global_pointer_bert import Dataset as arkData\n",
    "from ark_nlp.model.ner.global_pointer_bert import Tokenizer,GlobalPointerBertConfig,GlobalPointerBert,get_default_model_optimizer,Task,Predictor\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ner_list</th>\n",
       "      <th>type</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>血管内皮生长因子表达水平与宫颈癌患者预后的关系</td>\n",
       "      <td>[{'mention': '血管内皮生长因子表达水平与宫颈癌患者预后的关系', 'label...</td>\n",
       "      <td>Title</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>目的探讨地尔硫卓在治疗扩张型心肌病中的临床疗效。方法将2014年9月至2017年12月在红河...</td>\n",
       "      <td>[{'mention': '探讨地尔硫卓在治疗扩张型心肌病中的临床疗效', 'label':...</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>2501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>地尔硫卓在治疗扩张型心肌病中的临床疗效观察</td>\n",
       "      <td>[{'mention': '地尔硫卓在治疗扩张型心肌病中的临床疗效观察', 'label':...</td>\n",
       "      <td>Title</td>\n",
       "      <td>2501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                            血管内皮生长因子表达水平与宫颈癌患者预后的关系   \n",
       "1  目的探讨地尔硫卓在治疗扩张型心肌病中的临床疗效。方法将2014年9月至2017年12月在红河...   \n",
       "2                              地尔硫卓在治疗扩张型心肌病中的临床疗效观察   \n",
       "\n",
       "                                            ner_list      type  doc_id  \n",
       "0  [{'mention': '血管内皮生长因子表达水平与宫颈癌患者预后的关系', 'label...     Title    2500  \n",
       "1  [{'mention': '探讨地尔硫卓在治疗扩张型心肌病中的临床疗效', 'label':...  Abstract    2501  \n",
       "2  [{'mention': '地尔硫卓在治疗扩张型心肌病中的临床疗效观察', 'label':...     Title    2501  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=pd.read_json('./datasets/train.json')\n",
    "lens=len(df_test)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于W2NER\n",
    "result=[]\n",
    "for i in range(0,lens):\n",
    "    if df_test.loc[i,'type'] == 'Title':\n",
    "        text=df_test.loc[i,'text'].replace(' ','')\n",
    "        #token\n",
    "        sentence=[char for char in text]\n",
    "        #实体\n",
    "        ner=[]\n",
    "        for n in df_test.loc[i,'ner_list']:\n",
    "            entity=n['mention'].replace(' ','')\n",
    "            l=text.index(entity)\n",
    "            r=l+len(entity)\n",
    "            index=[j for j in range(l,r)]\n",
    "            type=n['label']\n",
    "            ner.append({\n",
    "                'index':index,\n",
    "                'type':type,\n",
    "            })\n",
    "        #分词\n",
    "        word=[]\n",
    "        split_word=jieba.tokenize(text)\n",
    "        for w in split_word:\n",
    "            widx=[j for j in range(w[1],w[2])]\n",
    "            word.append(widx)\n",
    "        #组装\n",
    "        result.append({\n",
    "            'sentence':sentence,\n",
    "            'ner':ner,\n",
    "            'word':word,\n",
    "        })\n",
    "result_json=json.dumps(result,ensure_ascii = False)\n",
    "with open('./datasets/w2ner/title_train.json','w',encoding='utf-8')as f:\n",
    "    f.write(result_json)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigcat=[]\n",
    "smallcat={\n",
    "    'C':[],\n",
    "    'I':[],\n",
    "    'O':[],\n",
    "    'P':[],\n",
    "    'S':[],\n",
    "}\n",
    "for i in range(0,lens):\n",
    "    if df_train.loc[i,'type'] == 'Title':\n",
    "        for ner in df_train.loc[i,'ner_list']:\n",
    "            l=ner['label'][0]\n",
    "            newbig={\n",
    "                'text':ner['mention'],\n",
    "                'label':l,\n",
    "            }\n",
    "            bigcat.append(newbig)\n",
    "            smallcat[l].append({\n",
    "                'text':ner['mention'],\n",
    "                'label':ner['label'][1:],\n",
    "            })\n",
    "    else:\n",
    "        for ner in df_train.loc[i,'ner_list']:\n",
    "            l=ner['label'][0]\n",
    "            curtext=ner['mention']\n",
    "            if len(curtext) > 200:\n",
    "                todel=len(curtext)-202\n",
    "                l=todel//2\n",
    "                r=todel-l\n",
    "                curtext=curtext[l:-r]\n",
    "            newbig={\n",
    "                'text':curtext,\n",
    "                'label':l,\n",
    "            }\n",
    "            bigcat.append(newbig)\n",
    "            smallcat[l].append({\n",
    "                'text':curtext,\n",
    "                'label':ner['label'][1:],\n",
    "            })\n",
    "big_json=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
